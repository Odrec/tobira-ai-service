# ============================================
# OpenAI Configuration
# ============================================
# Your OpenAI API key for AI-powered features (summaries, quizzes)
OPENAI_API_KEY=your-openai-api-key-here

# Default AI model to use for content generation
# Options: gpt-5.1 (recommended, uses new responses API), gpt-4, gpt-3.5-turbo, gpt-4-turbo, gpt-4o-mini
DEFAULT_MODEL=gpt-5.1

# ============================================
# Database Configuration
# ============================================
# PostgreSQL connection URL for Tobira's database
# Format: postgresql://username:password@host:port/database
DATABASE_URL=postgresql://tobira:tobira@localhost:5432/tobira

# ============================================
# Redis Configuration (Optional - for queue system)
# ============================================
# Redis server host for BullMQ job queue (optional)
# If Redis is not available, queue features will be disabled gracefully
REDIS_HOST=localhost

# Redis server port
REDIS_PORT=6379

# ============================================
# Server Configuration
# ============================================
# Port number for the AI service to listen on
PORT=3001

# Node environment (development, production, test)
NODE_ENV=development

# ============================================
# Performance Configuration
# ============================================
# Cache time-to-live in seconds for in-memory cache
# Controls how long transcripts, summaries, and quizzes are cached
CACHE_TTL_SECONDS=3600

# Maximum number of concurrent AI requests to prevent API overload
# Limits parallel OpenAI API calls to avoid rate limits
MAX_CONCURRENT_REQUESTS=5

# Request timeout in milliseconds for OpenAI API calls
# Prevents hanging requests from blocking the system
# Increased to 60 seconds for GPT-5.1 which may take longer to respond
REQUEST_TIMEOUT_MS=60000

# ============================================
# Queue Configuration (Phase 2)
# ============================================
# Number of concurrent workers processing queue jobs
# Controls how many AI generation tasks can run in parallel via queue
QUEUE_CONCURRENCY=2

# ============================================
# Feature Flags
# ============================================
# Master switch to enable/disable all AI features
# Can be overridden by database configuration
AI_FEATURES_ENABLED=true